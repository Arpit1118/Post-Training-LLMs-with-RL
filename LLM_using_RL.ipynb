{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arpit1118/Post-Training-LLMs-with-RL/blob/main/LLM_using_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jRp5V8SG4XD",
        "outputId": "6af28998-aaa9-46cf-8f32-442af23afe40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 1024)\n",
              "    (wpe): Embedding(1024, 1024)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-23): 24 x GPT2Block(\n",
              "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=3072, nx=1024)\n",
              "          (c_proj): Conv1D(nf=1024, nx=1024)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=4096, nx=1024)\n",
              "          (c_proj): Conv1D(nf=1024, nx=4096)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Core libraries\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Transformers from Hugging Face\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Evaluation and logging\n",
        "import time\n",
        "import traceback\n",
        "import logging\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# Using GPT-2 model (medium or large)\n",
        "MODEL_NAME = \"gpt2-medium\"  # or \"gpt2-large\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME)\n",
        "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn7kDzJcHR5w",
        "outputId": "405236d3-719f-4545-c056-472f0ab9acf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Math Solver Ready. Type 'exit' to quit.\n",
            ">>> x**3 - 6*x**2 + 11*x - 6 = 0\n",
            "Symbolic: [1, 2, 3]\n",
            "Numeric: [1.00000000000000, 2.00000000000000, 3.00000000000000]\n",
            ">>> tan(x) - sqrt(3) = 0\n",
            "Symbolic: [pi/3]\n",
            "Numeric: [1.04719755119660]\n",
            ">>> diff(sin(x)*cos(x), x)\n",
            "Result: -sin(x)**2 + cos(x)**2\n",
            ">>> integrate(x*exp(x), x)\n",
            "Result: (x - 1.0)*exp(x)\n",
            ">>> log(x**2 + 1) = 1\n",
            "Symbolic: [-sqrt(-1 + E), sqrt(-1 + E)]\n",
            "Numeric: [-1.31083249443209, 1.31083249443209]\n",
            ">>> (x + 1)**2 = x**2 + 2*x + 1\n",
            "Symbolic: []\n",
            "Numeric: []\n",
            ">>> sqrt(x) + sqrt(x + 1) = 2\n",
            "Symbolic: [9/16]\n",
            "Numeric: [0.562500000000000]\n",
            ">>> (x - sqrt(3))*(x + sqrt(3)) = 0\n",
            "Symbolic: [-sqrt(3), sqrt(3)]\n",
            "Numeric: [-1.73205080756888, 1.73205080756888]\n",
            ">>> quit\n"
          ]
        }
      ],
      "source": [
        "import sympy as sp\n",
        "\n",
        "class MathSolver:\n",
        "    def __init__(self, variable='x'):\n",
        "        self.x = sp.Symbol(variable)\n",
        "\n",
        "    def solve_equation(self, equation_str):\n",
        "        \"\"\"\n",
        "        Solves an equation like 'x**2 - 4 = 0' or 'sin(x) = 0'\n",
        "        Returns symbolic and numeric solutions\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if '=' in equation_str:\n",
        "                lhs, rhs = equation_str.split('=')\n",
        "                expr = sp.sympify(lhs) - sp.sympify(rhs)\n",
        "            else:\n",
        "                expr = sp.sympify(equation_str)\n",
        "\n",
        "            roots = sp.solve(expr, self.x)\n",
        "            numeric = [sp.N(r) for r in roots]\n",
        "\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"symbolic\": roots,\n",
        "                \"numeric\": numeric,\n",
        "                \"error\": None\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"symbolic\": None,\n",
        "                \"numeric\": None,\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "    def evaluate_expression(self, expr_str):\n",
        "        \"\"\"\n",
        "        Evaluates a basic math expression like '2 + 3 * 4'\n",
        "        \"\"\"\n",
        "        try:\n",
        "            result = sp.sympify(expr_str).evalf()\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"result\": result,\n",
        "                \"error\": None\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"result\": None,\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "# Example REPL\n",
        "if __name__ == \"__main__\":\n",
        "    solver = MathSolver()\n",
        "    print(\"Math Solver Ready. Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        inp = input(\">>> \")\n",
        "        if inp.lower() in ['exit', 'quit']:\n",
        "            break\n",
        "        if '=' in inp:\n",
        "            out = solver.solve_equation(inp)\n",
        "            if out[\"success\"]:\n",
        "                print(f\"Symbolic: {out['symbolic']}\")\n",
        "                print(f\"Numeric: {out['numeric']}\")\n",
        "            else:\n",
        "                print(\"Error:\", out[\"error\"])\n",
        "        else:\n",
        "            out = solver.evaluate_expression(inp)\n",
        "            if out[\"success\"]:\n",
        "                print(\"Result:\", out[\"result\"])\n",
        "            else:\n",
        "                print(\"Error:\", out[\"error\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def is_math_prompt(self, prompt):\n",
        "    # Strip to remove accidental spacing\n",
        "    prompt = prompt.strip().lower()\n",
        "\n",
        "    # If it's very short and numeric, it's likely a math query\n",
        "    if prompt.isdigit():\n",
        "        return True\n",
        "\n",
        "    # If it looks like a math expression with operators or equal signs\n",
        "    math_pattern = r\"[0-9xX\\+\\-\\*/\\^=()]\"\n",
        "    if re.search(math_pattern, prompt) and not re.search(r'[a-z]{3,}', prompt):  # ignore full sentences\n",
        "        return True\n",
        "\n",
        "    # If it ends with a question mark but has math symbols, still likely not math\n",
        "    if '?' in prompt and not re.search(r'\\d|\\+|\\-|\\*|/', prompt):\n",
        "        return False\n",
        "\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "sviF79rXN-74"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2MathWrapper:\n",
        "    def __init__(self, model, tokenizer, math_solver):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.math_solver = math_solver\n",
        "\n",
        "    def is_math_prompt(self, prompt):\n",
        "        import re\n",
        "        prompt = prompt.strip().lower()\n",
        "        if prompt.isdigit():\n",
        "            return True\n",
        "        math_pattern = r\"[0-9xX\\+\\-\\*/\\^=()]\"\n",
        "        if re.search(math_pattern, prompt) and not re.search(r'[a-z]{3,}', prompt):\n",
        "            return True\n",
        "        if '?' in prompt and not re.search(r'\\d|\\+|\\-|\\*|/', prompt):\n",
        "            return False\n",
        "        return False\n",
        "\n",
        "    def run(self, prompt):\n",
        "        if self.is_math_prompt(prompt):\n",
        "            if '=' in prompt:\n",
        "                result = self.math_solver.solve_equation(prompt)\n",
        "                if result[\"success\"]:\n",
        "                    return f\"Symbolic: {result['symbolic']}\\nNumeric: {result['numeric']}\"\n",
        "                else:\n",
        "                    return f\"Math Error: {result['error']}\"\n",
        "            else:\n",
        "                result = self.math_solver.evaluate_expression(prompt)\n",
        "                if result[\"success\"]:\n",
        "                    return f\"Result: {result['result']}\"\n",
        "                else:\n",
        "                    return f\"Math Error: {result['error']}\"\n",
        "        else:\n",
        "            # Use GPT-2 for general text\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "            outputs = self.model.generate(inputs, max_length=100, num_return_sequences=1)\n",
        "            return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "Cm7W7H1tO6gs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AM4fDpUvO-ol"
      },
      "execution_count": 4,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBa9N5RVqh7wUD3NLhsLxX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}